{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6I0FvdkwVOPe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Carregamento e pré-processamento dos dados"
      ],
      "metadata": {
        "id": "6I0FvdkwVOPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/denkuznetz/food-delivery-time-prediction"
      ],
      "metadata": {
        "id": "51RRFTPrTDbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJOVt0AsG_nT"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"denkuznetz/food-delivery-time-prediction\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Listar os arquivos no diretório\n",
        "files = os.listdir(path)\n",
        "print(\"Arquivos no diretório:\", files)"
      ],
      "metadata": {
        "id": "l_SqYgg7HC1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3bmClWw0HnQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = os.path.join(path, 'Food_Delivery_Times.csv')\n",
        "\n",
        "df = pd.read_csv(csv_file_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FD2HZeYTJ_NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Remover a coluna Order_ID\n",
        "df.drop(columns=['Order_ID'], inplace=True)\n",
        "\n",
        "# Substituir valores nulos em \"Courier_Experience_yrs\" pela mediana\n",
        "imputer_num = SimpleImputer(strategy=\"median\")\n",
        "df[\"Courier_Experience_yrs\"] = imputer_num.fit_transform(df[[\"Courier_Experience_yrs\"]])\n",
        "\n",
        "# Substituir valores nulos em variáveis categóricas pela moda\n",
        "categorical_cols = [\"Weather\", \"Traffic_Level\", \"Time_of_Day\"]\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
        "\n",
        "# Aplicar One-Hot Encoding nas variáveis categóricas\n",
        "df = pd.get_dummies(df, columns=[\"Weather\", \"Traffic_Level\", \"Time_of_Day\", \"Vehicle_Type\"], drop_first=True)\n",
        "\n",
        "# Exibir as primeiras linhas do dataframe processado\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "REo5w0_yO0lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        # If column is of object type, try converting to numeric\n",
        "        try:\n",
        "            df[col] = pd.to_numeric(df[col])\n",
        "        except ValueError:\n",
        "            # If conversion fails, handle the non-numeric values (e.g., replace with NaN or a specific value)\n",
        "            # Here, we replace non-numeric values with NaN and then fill them with the column's median\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert non-numeric to NaN\n",
        "            df[col] = df[col].fillna(df[col].median())  # Fill NaN with median"
      ],
      "metadata": {
        "id": "KpO_zbJ5eKpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns=['Delivery_Time_min']).values\n",
        "y = df['Delivery_Time_min'].values\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RS0LCN9hWp6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "Ydw76HvOYUN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando as três primeiras colunas (dados contínuos)\n",
        "continuous_indices = [0, 1, 2]\n",
        "\n",
        "# Aplicando MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train[:, continuous_indices] = scaler.fit_transform(X_train[:, continuous_indices])\n",
        "X_test[:, continuous_indices] = scaler.transform(X_test[:, continuous_indices])"
      ],
      "metadata": {
        "id": "TqDzhFb0YW7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizando o alvo\n",
        "y_min = y_train.min()\n",
        "y_max = y_train.max()\n",
        "\n",
        "y_train = (y_train - y_min) / (y_max - y_min)\n",
        "y_test = (y_test - y_min) / (y_max - y_min)\n"
      ],
      "metadata": {
        "id": "ML5QjHOIbwG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "metadata": {
        "id": "F--0yVaXehcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O problema"
      ],
      "metadata": {
        "id": "V7za_nJicItT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!['Moto'](https://i.imgur.com/kGUQ2wj.png)"
      ],
      "metadata": {
        "id": "WtuJI_W2cFxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine uma cidade grande e agitada, onde os moradores estão sempre em movimento e dependem de serviços de entrega rápida para suas refeições. A **Run Food Run**, uma empresa de entregas por aplicativo, enfrenta diariamente o desafio de garantir que seus motoboys entreguem pedidos no menor tempo possível, mantendo a qualidade do serviço.\n",
        "\n",
        "No entanto, prever o tempo de entrega não é uma tarefa simples. Diversos fatores influenciam esse processo: o clima, o horário do dia, a distância entre o restaurante e o cliente, o tráfego nas ruas, e até mesmo o histórico de desempenho dos motoboys. A empresa percebeu que, para continuar competitiva, precisava de uma solução tecnológica que ajudasse a prever os tempos de entrega com maior precisão.\n",
        "\n",
        "E é aqui que entra o poder das **redes neurais**. Utilizando dados históricos de entregas, como características das rotas e tempos registrados, a Run Food Run decidiu criar um modelo de regressão baseado em aprendizado de máquina. O objetivo? Prever com precisão o tempo que um motoboy levará para entregar um pedido, antes mesmo de ele sair do restaurante.\n",
        "\n",
        "Com isso, a empresa poderia:\n",
        "- **Aumentar a eficiência**: Alocar os motoboys de forma mais estratégica, reduzindo atrasos.\n",
        "- **Melhorar a experiência do cliente**: Fornecer previsões mais precisas sobre o tempo de entrega.\n",
        "- **Otimizar recursos**: Identificar padrões que poderiam ser ajustados para melhorar os tempos médios de entrega.\n",
        "\n",
        "Neste projeto, você será transportado para o coração desse desafio. Usando o **PyTorch**, uma das ferramentas mais poderosas para aprendizado de máquina, você irá realizar a construção de uma rede neural capaz de transformar dados brutos em previsões úteis e práticas.\n"
      ],
      "metadata": {
        "id": "3Gc8SwVc3HX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 1: Convertendo Dados para Tensores do PyTorch"
      ],
      "metadata": {
        "id": "WfExt5oUcOO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo para trabalharmos com o PyTorch é converter os dados de treino e teste (`X_train`, `X_test`, `y_train` e `y_test`) em **tensores**, que são a estrutura de dados fundamental no PyTorch. Os tensores permitem que o PyTorch realize operações matemáticas otimizadas, aproveitando o poder de GPUs para acelerar os cálculos.\n",
        "\n",
        "Sua tarefa é:\n",
        "1. Converter os conjuntos de entrada (`X_train` e `X_test`) e saída (`y_train` e `y_test`) em tensores do PyTorch.\n",
        "2. Garantir que os tensores de saída (`y_train` e `y_test`) tenham a forma correta para serem usados no modelo (dica: você pode usar `.view(-1, 1)` para ajustar a dimensão).\n",
        "\n",
        "#### Dica:\n",
        "Você pode usar a função `torch.tensor()` para realizar a conversão. Não se esqueça de especificar o tipo de dado como `torch.float32`, pois o PyTorch trabalha melhor com esse formato em problemas de aprendizado de máquina."
      ],
      "metadata": {
        "id": "5tCY-6NU4FfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "716S4Eoqcbxz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lw6S4zWecg1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHR-zbWvb3ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNtx3AKchDh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 2: Criando o Dataset e o DataLoader"
      ],
      "metadata": {
        "id": "k7nH8SHhjapK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que os dados foram convertidos para tensores, o próximo passo é organizá-los de forma eficiente para serem usados durante o treinamento do modelo. Para isso, utilizaremos as classes **`Dataset`** e **`DataLoader`** do PyTorch.\n",
        "\n",
        "#### Sua tarefa:\n",
        "1. **Criar um Dataset personalizado**: Use a classe `torch.utils.data.Dataset` para criar um conjunto de dados que armazene os tensores de entrada (`X_train_tensor`, `X_test_tensor`) e saída (`y_train_tensor`, `y_test_tensor`).\n",
        "2. **Criar DataLoaders**: Use a classe `DataLoader` para carregar os dados em lotes (*batches*), o que é essencial para treinar modelos de forma eficiente.\n",
        "\n",
        "#### Dicas:\n",
        "- Para criar o Dataset, você precisará implementar os métodos `__len__` (que retorna o tamanho do dataset) e `__getitem__` (que retorna uma amostra específica do dataset com base no índice).\n",
        "- O DataLoader permite que você carregue os dados em lotes e, no caso do conjunto de treino, pode embaralhá-los para melhorar o treinamento.\n",
        "\n",
        "Consultar o tópico: Creating a Simple Dataset Class\n",
        "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/"
      ],
      "metadata": {
        "id": "IB7l8xonj9WO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uV76hx9Ger4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar DataLoaders:\n",
        "Os DataLoaders permitem carregar os dados em lotes (batches) e embaralhá-los durante o treinamento."
      ],
      "metadata": {
        "id": "-O8yozSOkE31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.geeksforgeeks.org/how-to-use-a-dataloader-in-pytorch/"
      ],
      "metadata": {
        "id": "zhn79M_d7FQc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0WODZgxj4ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 3: Definindo o Modelo"
      ],
      "metadata": {
        "id": "IgUITMm8lAls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que os dados estão organizados e prontos para uso, o próximo passo é definir o modelo de rede neural. Para isso, utilizaremos o **PyTorch** para criar uma arquitetura simples, mas poderosa, capaz de realizar previsões em um problema de regressão.\n",
        "\n",
        "#### Sua tarefa:\n",
        "1. **Definir a arquitetura do modelo**: Crie uma classe que herda de `torch.nn.Module` e implemente as camadas da rede neural.\n",
        "2. **Configurar as camadas**: Para um problema de regressão, a última camada deve ter **1 unidade de saída** (saída linear, sem função de ativação).\n",
        "3. **Adicionar funções de ativação**: Use funções de ativação como `ReLU` entre as camadas ocultas para introduzir não-linearidades.\n",
        "\n",
        "#### Dicas:\n",
        "- Use a classe `nn.Sequential` para organizar as camadas de forma simples.\n",
        "- A arquitetura pode começar com uma camada de entrada (tamanho igual ao número de *features*), seguida por algumas camadas ocultas, e terminar com uma camada de saída.\n",
        "\n",
        "#### Tarefa prática:\n",
        "1. Defina o modelo usando a classe `torch.nn.Module`.\n",
        "2. Certifique-se de que o número de entradas da primeira camada (`input_size`) seja igual ao número de *features* do seu conjunto de dados.\n",
        "3. Inicialize o modelo e verifique se ele está pronto para receber entradas.\n",
        "\n",
        "#### Dica extra:\n",
        "Para inicializar o modelo, você pode usar:\n",
        "```python\n",
        "input_size = X_train_tensor.shape[1]  # Número de *features* no conjunto de treino\n",
        "model = RegressionModel(input_size)\n",
        "```\n"
      ],
      "metadata": {
        "id": "TLhES6NAlHw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html"
      ],
      "metadata": {
        "id": "isYCgok7-D8f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXlb1d8Rk9MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 4: Definir a função de custo e o otimizador"
      ],
      "metadata": {
        "id": "v6Iv5yQBl7lO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o modelo definido, é hora de configurar os elementos essenciais para o treinamento: a **função de custo** (ou função de perda) e o **otimizador**. Esses componentes irão guiar o modelo durante o aprendizado, ajustando os pesos para minimizar os erros nas previsões.\n",
        "\n",
        "#### Sua tarefa:\n",
        "1. **Escolher a função de custo**: Para um problema de regressão, uma boa escolha é o **Erro Quadrático Médio (MSE)**, que mede a diferença entre as previsões do modelo e os valores reais.\n",
        "2. **Definir o otimizador**: O otimizador é responsável por ajustar os pesos do modelo com base no gradiente da função de custo. O **Adam** é uma escolha popular e eficiente.\n",
        "\n",
        "#### Dicas:\n",
        "- A função de custo pode ser definida usando `torch.nn.MSELoss()`.\n",
        "- O otimizador pode ser configurado com `torch.optim.Adam()`, passando os parâmetros do modelo (`model.parameters()`) e a taxa de aprendizado (`learning_rate`).\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html\n",
        "\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html\n"
      ],
      "metadata": {
        "id": "xWpdV0g_mawC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kenaQW2YllYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 5: Treinar o modelo"
      ],
      "metadata": {
        "id": "q6ls6TNgnCjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que o modelo, a função de custo e o otimizador estão configurados, é hora de realizar o treinamento! O objetivo aqui é ajustar os pesos do modelo para minimizar o erro nas previsões, utilizando os dados de treino.\n",
        "\n",
        "#### Tarefa prática:\n",
        "1. Configure o número de *épocas* (ex.: `num_epochs = 100`).\n",
        "2. Use o `DataLoader` para iterar sobre os lotes do conjunto de treino.\n",
        "3. Para cada lote:\n",
        "   - Faça a previsão (`forward pass`).\n",
        "   - Calcule a perda.\n",
        "   - Realize o retropropagação (`backward pass`) e atualize os pesos.\n",
        "4. Monitore a perda ao longo das épocas para garantir que o modelo está aprendendo.\n",
        "\n",
        "#### Dica extra:\n",
        "- Você pode adicionar validação ao final de cada época, utilizando o `test_loader` para verificar o desempenho do modelo nos dados de teste.\n",
        "\n",
        "Consultar Training Loop:\n",
        "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n"
      ],
      "metadata": {
        "id": "0xn5n6wHnGMs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRlUljZzmFJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 6: Avaliar o modelo"
      ],
      "metadata": {
        "id": "GbJc9syCp3us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após o treinamento do modelo, é essencial avaliar seu desempenho para entender como ele se comporta nos dados de teste (ou validação). Isso ajuda a garantir que o modelo está generalizando bem e não apenas \"decorando\" os dados de treino.\n",
        "\n",
        "#### Sua tarefa:\n",
        "1. **Colocar o modelo em modo de avaliação**: Use `model.eval()` para desativar componentes como *dropout* (caso existam) e garantir que o modelo funcione de forma determinística.\n",
        "2. **Calcular métricas de desempenho**: Para problemas de regressão, a métrica mais comum é o **Erro Quadrático Médio (MSE)** ou o **Erro Absoluto Médio (MAE)**. Você também pode calcular o **R² (coeficiente de determinação)** para avaliar o ajuste geral.\n",
        "3. **Evitar gradientes durante a avaliação**: Use `torch.no_grad()` para evitar o cálculo de gradientes, o que economiza memória e acelera a avaliação.\n",
        "\n",
        "https://yassin01.medium.com/understanding-the-difference-between-model-eval-and-model-train-in-pytorch-48e3002ee0a2"
      ],
      "metadata": {
        "id": "aGiF-o9Dp6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "naHgkGiJp0PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa 7: Fazer previsões"
      ],
      "metadata": {
        "id": "fTbNhfBlrVJp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DGVrPkNQp7_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3VGlRZqqNmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}